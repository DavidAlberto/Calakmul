---
author: "David Alberto García Estrada (david.garcia.e@cinvestav.mx)"
header-includes:
- \usepackage{mathtools}
- \usepackage{amsthm}
- \usepackage{amssymb}
- \usepackage{eufrak}
- \usepackage{mathrsfs}
- \usepackage{color}
- \usepackage[spanish]{babel}
- \usepackage{fancyhdr}
- \usepackage{array}
- \usepackage{subfigure} %para incluir mas de una figura en un solo espacio
- \usepackage{graphicx}
- \allowdisplaybreaks
- \usepackage{float}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
- \newtheorem{teorema}{Teorema}
- \newtheorem{lema}[teorema]{Lema}
- \newtheorem{corolario}[teorema]{Corolario}
- \newtheorem{proposicion}[teorema]{Proposici\'on}
- \newtheorem{conjetura}[teorema]{Conjetura}
- \newtheorem{definicion}{Definici\'on}
- \newtheorem{ejemplo}[teorema]{Ejemplo}
- \newtheorem{nota}{Nota}
output:
  pdf_document:
    toc_depth: 2
    number_sections: yes
    df_print: kable
    highlight: tango
    fig_caption: yes
  html_document:
    toc_depth: '2'
    df_print: paged
urlcolor: blue
---

\newcommand{\cb}{\color{blue}}
\newcommand{\cg}{\color{green}}
\newcommand{\cvi}{\color{violet}}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include = FALSE, echo = FALSE}
##  LIBRERÍAS
# Aquí vamos a incluir las librerías que necesitemos
# En donde se pongan pedazos de código, únicamente se comentará
# Es BUENA PRÁCTICA poner las librerías al principio, por ello las ponemos aquí
# Primero deben asegurarse de tener instalados todos los paquetes

## Repositorio CRAN
cran_packages <- c("bookdown", "knitr", "tidyverse", "plyr", "grid", "gridExtra", "kableExtra", "xtable", "ggpubr")
## Repositorio Bioconductor
bioc_packages <- c("phyloseq", "dada2", "DECIPHER", "phangorn", "ggpubr", "BiocManager","DESeq2", "microbiome", "philr")
## Repositorio GitHub
git_source <- c("twbattaglia/btools", "gmteunisse/Fantaxtic", "MadsAlbertsen/ampvis2", "opisthokonta/tsnemicrobiota")
# fuente/nombre del paquete
git_packages <- c("btools", "fantaxtic", "ampvis2", "tsnemicrobiota") #Nombre del paquete
sapply(c(cran_packages, bioc_packages, git_packages), require, character.only = TRUE)
library("phyloseq")
library("ggplot2")
library("readr")
library("patchwork")
library("pheatmap")
library("microbiome")
library("xtable")
library("tsnemicrobiota")
library("Rtsne")
library("ampvis2")
library("btools")
```

<!-- AQUÍ INICIA LA PÁGINA DE TÍTULO
  Indicaciones:
          El nombre de los autores aparece al principio
-->

\title{ {\sc Análisis de Metageómico}\\
\vspace{1cm}{\sc Calakmul}\\ 
\vspace{1cm}{\sc Amplicón rRNA 16s}\\
   \vspace{1.5cm} {UGA - LANGEBIO CINVESTAV } \\
       \vspace{1.5cm} {}\\[2cm]
       }
  
\date{\vspace{5.5cm} Irapuato, Guanajuato, México\\
      \vspace{1cm} Septiembre de 2022}

 \maketitle
 

\thispagestyle{fancy}
\newpage

<!-- FIN DE LA PÁGINA DE  TÍTULO-->

<!-- INICIO ÍNDICE -->

\tableofcontents
\newpage
<!-- FIN INDICE -->



<!-- INICIO DOCUMENTO -->

# Introducción

Análisis de datos de rRNA 16s con las paqueterias de `DADA2` y `Mothur`, basado en curso de [CastroLab](http://www.castrolab.org/isme/dada2/dada2.html) y el paper [Bioconductor Workflow for Microbiome Data Analysis: from raw reads to community analyses](https://f1000research.com/articles/5-1492/v2).

## Microbioma 

El microbioma está formado por comunidades ecológicas de microrganismos. En la actualidad, las bacterias pueden identificarse mediante el uso de la secuenciación de nueva generación aplicada a varios niveles. La secuenciación Shotgun de todas las bacterias de una muestra permite conocer todos los genes presentes. Aquí sólo nos interesará la identificación y la cuantificación de taxones individuales (o especies) a través de un "gen de huella digital" llamado 16s rRNA que está presente en todas las bacterias. Este gen presenta varias regiones variables que pueden utilizarse para identificar los distintos taxones. 
Los flujos de trabajo estándar anteriores dependían de la agrupación de todas las secuencias de ARNr 16s (generadas por la secuenciación de amplicones de próxima generación de próxima generación) que se encuentran dentro de un radio de similitud del 97% y, a continuación, asignarlas a "OTU" a partir de árboles de referencia. Estos enfoques no incorporan todos los datos, en particular la información sobre la calidad de la secuencia y la información estadística disponibles en las lecturas no se incorporaron a las asignaciones. 
En cambio, los recuentos de lecturas *de novo* utilizados aquí se construirán mediante la incorporación tanto de las puntuaciones de calidad y las frecuencias de las secuencias en un modelo de ruido probabilístico para las transiciones de nucleótidos. 
Después de filtrar las secuencias y eliminar las quimeras, los datos se comparan con una base de datos estándar de bacterias y etiquetados. Aquí usamos las secuencias etiquetadas para construir una filogenia *de novo* con el *phangorn*.
El paso clave en el análisis de las secuencias es la forma en que las lecturas se denotan y se ensamblan en grupos que hemos decidido llamar RSV (Variantes de Secuencia Ribosómica) en lugar de las tradicionales OTU (Unidades Taxonómicas Operativas).
Aquí describimos el flujo de trabajo computacional para realizar la **eliminación de ruido**, el **filtrado**, las **transformaciones de datos**, la **visualización**, los **análisis de aprendizaje supervisado**, las **pruebas de redes comunitarias**, las **pruebas jerárquicas** y los **modelos lineales**. 

## Paqueterias

Definimos los paquetes que se utilizarán

```{r}
## Repositorio CRAN
cran_packages <- c("bookdown", "knitr", "tidyverse", "plyr", "grid", "gridExtra", "kableExtra", "xtable", "ggpubr")
## Repositorio Bioconductor
bioc_packages <- c("phyloseq", "dada2", "DECIPHER", "phangorn", "ggpubr", "BiocManager","DESeq2", "microbiome", "philr")
## Repositorio GitHub
git_source <- c("twbattaglia/btools", "gmteunisse/Fantaxtic", "MadsAlbertsen/ampvis2", "opisthokonta/tsnemicrobiota")
# fuente/nombre del paquete
git_packages <- c("btools", "fantaxtic", "ampvis2", "tsnemicrobiota") #Nombre del paquete
```

Instalamos los paquetes, para ello es necesario que descomentes las siguientes líneas.

```{r}
# # Intalar paquetes CRAN
# .inst <- cran_packages %in% installed.packages()
# if(any(!.inst)) {
#   install.packages(cran_packages[!.inst])
# }
# # Intalar paquetes BioConductor
# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# .inst <- bioc_packages %in% installed.packages()
# if(any(!.inst)) {
#   BiocManager::install(bioc_packages[!.inst])
# }
# # Instalar paquetes GitHub
# .inst <- git_source %in% installed.packages()
# install.packages("devtools")
# if(any(!.inst)) {
#   devtools::install_github(git_source[!.inst])
# }
# library("devtools")
# install_github("opisthokonta/tsnemicrobiota")
# install.packages("remotes")
# remotes::install_github("kasperskytte/ampvis2")
# devtools::install_github('twbattaglia/btools')
```

Cargamos los paquetes

```{r}
sapply(c(cran_packages, bioc_packages, git_packages), require, character.only = TRUE)
library("phyloseq")
library("ggplot2")
library("readr")
library("patchwork")
library("pheatmap")
library("microbiome")
library("xtable")
library("tsnemicrobiota")
library("Rtsne")
library("ampvis2")
library("btools")
```

# DADA2

El paquete **DADA2** infiere las variantes exactas de la secuencia de amplicones (ASVs) a partir de datos de secuenciación de amplicones de alto rendimiento, sustituyendo el enfoque de agrupación de OTUs, más grueso y menos preciso. La línea de producción **DADA2** toma como entrada archivos fastq desmultiplexados, y produce las variantes de secuencia y sus abundancias en las muestras después de eliminar los errores de sustitución y quimera. La clasificación taxonómica está disponible a través de una implementación nativa del clasificador bayesiano ingenuo RDP, y la asignación a nivel de especie de los fragmentos del gen 16S rRNA por coincidencia exacta.

**DADA2** ofrece ventajas con respecto a la estrategia de formar clusters (OTUs) en varios aspectos que incluyen *mayor resolución*, *nombres consistentes entre diferentes análisis*, *mejor estimación de abundancias relativas*, etc. 

## Directorio de trabajo

Ajustamos directorio de trabajo donde se encuentran las lecturas "reads"
```{r}
# IMPORTANTE
# Ajustamos path de trabajo según tu PC
# Mostramos directorio actual
getwd()
# Si es necesario, cambiar la ruta donde están los archivos almacenados. 
# "." significa el directorio actual. 
workingDir <-  "."
setwd(workingDir)
# Creamos directorio de Resultados y otras capertas
dir.create("Resultados/")
dir.create("Resultados/Dendogramas/")
# Asignamos la carpeta donde están las lecturas crudas
miseq_path <- "RawData"
list.files(miseq_path)
```

## Ordenamos las lecturas

En **DADA2** las lecturas se trabajan inicialmente por separado, es decir, la copia Forward o R1 separada de la copia Reverse o R2. Por esto, nos tenemos que asegurar que ambos archivos estén ordenados. Luego, manipulamos el nombre de los archivos para generar automáticamente el nombre de las muestras en nuestro análisis:

```{r}
# Ordenamos los nombres de los archivos y los metemos a una variable
fnFs <- sort(list.files(miseq_path, pattern="_R1.fastq.gz"))
fnRs <- sort(list.files(miseq_path, pattern="_R2.fastq.gz"))

# Extracción del nombre de las muestras
sampleNames <- sapply(strsplit(fnFs, "_R"), `[`, 1)
sampleNames

# Especificamos el path completo para evitar errores de ambigüedad
fnFs <- file.path(miseq_path, fnFs)
fnRs <- file.path(miseq_path, fnRs)
fnFs
fnRs
```

## Visualización de calidad

El paquete **DADA2** tiene muchas funciones útiles para el pre-procesamiento de los datos. A continuación se visualiza el perfil de calidad de las muestras para cada par de 5’ a 3’:

```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Perfil de calidad de las lecturas de dos archivos fastq.'}
plotQualityProfile(fnFs[1:2]) #Solo de las primeras 2  
plotQualityProfile(fnRs[1:2]) #Solo de las primeras 2 
```

## Filtrado y corte

Ahora vamos a proceder con el filtrado y corte de las lecturas de acuerdo a lo observado en los gráficos de calidad. Primero creamos un directorio donde vamos a poner las lecturas una vez realizado el control de calidad, y luego realizamos dicho control. En específico usamos los argumentos 
+ trunLen = corte promedio de cada read
+ maxN = número máximo de bases indeterminadas
+ maxEE = número máximo de errores
+ truncQ = Corta lecturas que el valor de calidad es menor a un valor
+ rm.phix = si es que queremos remover secuencias pertenecientes al control interno de Illumina

```{r}
# Creamos un directorio para poner las lecturas "limpias"
filt_path <- file.path("Filtered/") 
filt_path

if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(sampleNames, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sampleNames, "_R_filt.fastq.gz"))

# Y finalmente procedemos con el control de calidad
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen = c(300,250),
              maxN = 0, maxEE = c(2,2), truncQ = 2, rm.phix = TRUE,
              compress = TRUE, multithread = FALSE) 
# Si usan Windows, configuren multithread=FALSE
```

**DADA2** genera un modelo probabilístico de errores con el cual puede filtrar lecturas erróneas y así usar las restantes directamente para la etapa de clasificación taxonómica. Esta parte del método es la que nos permite tener una mayor resolución en comparación a los análisis basados en OTUs. 

## De-replicar

Como las muestras probablemente tienen lecturas idénticas, no es eficiente usar cada una de ellas para los pasos río abajo. Por esto, **DADA2** recomienda *de-replicar* las muestras para así disminuir la redundancia y avanzar eficientemente.

```{r}
# De-replicar
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)

# Agregamos los nombres de las muestras al objeto de-replicado
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames
```

Una vez con las muestras de-replicadas procedemos a generar un modelo de errores. Para mayor detalle sobre este crucial paso revisen el artículo original [aquí](https://www.nature.com/articles/nmeth.3869).

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)

# Graficamos los errores para cada par
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
```

Se muestran las tasas de error para cada transición posible (A→C, A→G, …). Los puntos son las tasas de error observadas para cada puntaje de calidad de consenso. La línea negra muestra las tasas de error estimadas después de la convergencia del algoritmo de aprendizaje automático. La línea roja muestra las tasas de error esperadas según la definición nominal de la puntuación Q. 
Aquí, las tasas de error estimadas (línea negra) NO SE AJUSTA bien a las tasas observadas (puntos), y las tasas de error disminuyen con una mayor calidad pero NO como se esperaba. 

## Amplicon Sequence Variants (ASVs)

Con esta información procedemos al paso más importante de la pipeline, **la inferencia de las Amplicon Sequence Variants (ASVs)**. El método de inferencia de secuencias **DADA2** puede funcionar en dos modos diferentes: *Inferencia independiente por muestra* (`pool=FALSE`), y la *inferencia a partir de las lecturas de secuenciación agrupadas de todas las muestras* (`pool=TRUE`). La inferencia independiente tiene la ventaja de que el tiempo de cálculo es lineal en el número de muestras, y los requisitos de memoria son planos con el número de muestras. Esto permite escalar a conjuntos de datos de tamaño casi ilimitado. La inferencia conjunta es más exigente desde el punto de vista computacional y puede llegar a ser intratable para conjuntos de datos de decenas de millones de lecturas. Sin embargo, la agrupación mejora la detección de variantes raras que se observan sólo una o dos veces en una muestra individual, pero muchas veces en todas las muestras. 

```{r}
dadaFs <- dada(derepFs, err=errF, multithread=TRUE, pool = TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE, pool = TRUE)
```

Inspeccionando el objeto de clase `dada` devuelto: 

```{r}
dadaFs[[1]]
dadaRs[[1]]
```

El algoritmo **DADA2** infirió 3043 variantes de secuencia verdadera de las secuencias únicas de 37332 en la primera muestra y 2200 variantes de secuencia verdadera de las secuencias únicas de 38947 en la segunda muestra. Hay mucho más en el objeto de retorno de la clase *dada*, incluidos múltiples diagnósticos sobre la calidad de cada variante de secuencia eliminada.

## Combinar lecturas emparejadas

Ahora fusionamos las lecturas directa y reversa para obtener las secuencias completas sin ruido. La fusión se realiza alineando las *lecturas directas eliminadas de ruido* con el *complemento reverso de las lecturas reversas eliminadas de ruido correspondientes*, y luego construyendo las secuencias "contig" fusionadas. De forma predeterminada, las secuencias fusionadas solo se emiten si las lecturas directa e inversa se superponen en al menos 12 bases y son idénticas entre sí en la región de superposición (pero estas condiciones se pueden cambiar a través de argumentos de función). 

```{r}
# Unimos las reads
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)
```

El objeto de `mergers` es una lista de marcos de datos de cada muestra. Cada data.frame contiene la `$sequence`, su `$abundance` y los índices de las variantes de secuencia `$forward` y `$reverse` que se fusionaron. `mergePairs` eliminó las lecturas emparejadas que no se superponían exactamente, lo que redujo aún más la salida espuria. 

## Construir tabla de secuencia

Ahora podemos construir una tabla de variantes de secuencia de amplicón (ASV), una versión de mayor resolución de la tabla OTU producida por métodos tradicionales.

```{r}
# Generamos una tabla de secuencias
seqtabAll <- makeSequenceTable(mergers[!grepl("Mock", names(mergers))])
dim(seqtabAll)
table(nchar(getSequences(seqtabAll)))
```

La tabla de secuencias es una matriz con filas correspondientes a (y nombradas por) las muestras y columnas correspondientes (y nombradas por) las variantes de secuencia. 

## Removemos quimeras

El método `dada` corrige errores de sustitución e indel (insersión / deleción), pero quedan quimeras (producto de la amplificación por PCR). Afortunadamente, la precisión de las variantes de secuencia después de eliminar el ruido hace que identificar ASV quiméricos sea más simple que cuando se trata de OTU difusas. Las secuencias quiméricas se identifican si pueden reconstruirse exactamente combinando un segmento izquierdo y un segmento derecho de dos secuencias "primarias" más abundantes. 

```{r}
seqtabNoC <- removeBimeraDenovo(seqtabAll, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtabNoC)
sum(seqtabNoC)/sum(seqtabAll)
```

La frecuencia de las secuencias quiméricas varía sustancialmente de un conjunto de datos a otro y depende de factores que incluyen los procedimientos experimentales y la complejidad de la muestra. Cuando tomamos en cuenta la abundancia de esas variantes, vemos que representan alrededor del 22 % de las lecturas de secuencias fusionadas.

## Seguimiento de lecturas por cada paso

Como verificación final de nuestro progreso, veremos la cantidad de lecturas que se realizaron en cada paso: 

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtabNoC))
# Si procesa una sola muestra, elimine las llamadas de sapply: p. reemplace sapply(dadaFs, getN) con getN(dadaFs) 
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sampleNames
head(track)
```

## Asignación Taxonómica

Es común en este punto, especialmente en la secuenciación de amplicón 16S/18S/ITS, asignar taxonomía a las variantes de secuencia. El paquete **DADA2** proporciona una implementación nativa del método *clasificador bayesiano ingenuo* para este propósito. La función de `assignTaxonomy` toma como entrada un conjunto de secuencias para clasificar y un conjunto de entrenamiento de secuencias de referencia con taxonomía conocida, y genera asignaciones taxonómicas con al menos `minBoot` bootstrap confianza.
Mantenemos fastas de entrenamiento formateados para el conjunto de entrenamiento *RDP*, *GreenGenes* agrupados en un 97 % de identidad y la base de datos de referencia *Silva*, y se han contribuido fastas de entrenamientos adicionales adecuados para protistas y ciertos entornos específicos. Para la taxonomía fúngica, los archivos de publicación de General Fasta de la base de datos *UNITE ITS* se pueden usar tal cual. 
Para continuar, descargue el archivo `silva_nr_v138_train_set.fa.gz` y colóquelo en el directorio con los archivos fastq. 
La *tabla de secuencias sin las quimeras*, es la tabla que usamos para realizar la clasificación taxonómica. En principio, podríamos usar cualquiera de las tres bases de datos más populares para clasificación de secuencias del 16S rRNA, i.e., GreenGenes, RDP o SILVA.

### SILVA versión 138

**SILVA** proporciona conjuntos de datos completos, de calidad comprobada y actualizados periódicamente de secuencias alineadas de RNA ribosomal (rRNA) pequeñas (16S/18S, SSU) y subunidades grandes (23S/28S, LSU) para los tres dominios de la vida (bacterias, arqueas y eucariotas). 

```{r}
fastaRef <- "Silva/silva_nr_v138_train_set.fa"
taxTab <- assignTaxonomy(seqtabNoC, refFasta = fastaRef, multithread=TRUE)
```

El paquete **DADA2** también implementa un método para realizar **asignaciones de nivel de especie** basadas en coincidencias exactas entre ASV y cepas de referencia secuenciadas. Un análisis reciente sugiere que la coincidencia exacta (o el 100 % de identidad) es la única forma adecuada de asignar especies a los fragmentos del gen 16S. Actualmente, los fastas de entrenamiento de asignación de especies están disponibles para las bases de datos **Silva** y **RDP** 16S. Para seguir el paso opcional de adición de especies, descargue el archivo `silva_species_assignment_v138.fa.gz` y colóquelo en el directorio con los archivos fastq. 

```{r}
# En el caso de querer agregar el rango taxonómico de especies, simplemente usamos una base de datos extra, la cual contiene esta información. 
taxTabExtra <- addSpecies(taxTab, "Silva/silva_species_assignment_v138.fa", verbose=TRUE)
unname(head(taxTab)) -> tabla
colnames(tabla) <- c("Kingdom", "Phylum", "Order", "Class", "Family", "Genus")
head(tabla)
```

**Alternativas**: El método de clasificación taxonómica `IdTaxa` desarrollado recientemente también está disponible a través del paquete *DECIPHER Bioconductor*. El documento que presenta el algoritmo **IDTAXA** informa un rendimiento de clasificación que es mejor que el estándar establecido durante mucho tiempo por el *clasificador bayesiano ingenuo*. Aquí incluimos un bloque de código que le permite usar `IdTaxa` como un reemplazo directo para `assignTaxonomy` (¡y también es más rápido!). Los clasificadores capacitados están disponibles en http://DECIPHER.codes/Downloads.html. Descargue el archivo SILVA SSU r132 (modificado) para continuar. 

```{r}
#library(DECIPHER); packageVersion("DECIPHER")
#dna <- DNAStringSet(getSequences(seqtabNoC)) # Crea un DNAStringSet desde el ASVs
#load("~/Documents/calakmul/16S/SILVA_SSU_r138_2019.RData") # Asignamos la dirección de archivo SSU modicado .RData
#ids <- IdTaxa(dna, trainingSet, strand="top", processors=NULL, verbose=FALSE) #  usar todos los procesadores
#ranks <- c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species") # rangos de interés
# Convierta el objeto de salida de la clase "Taxa" en una matriz análoga a la salida de AssignTaxonomy 
#taxid <- t(sapply(ids, function(x) {
#        m <- match(ranks, x$rank)
#        taxa <- x$taxon[m]
#        taxa[startsWith(taxa, "unclassified_")] <- NA
#        taxa
#}))
#colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtabNoC)
```

La matriz `taxid` de `IdTaxa` es un reemplazo directo de la matriz `taxa` de `AssignTaxonomy`, simplemente configure `taxa <- taxid` para continuar usando las asignaciones de `IdTaxa`.

## Árbol filogenético

Ya que nuestro perfil taxonómico se construye con secuencias homólogas del gen rRNA 16s, podemos usar estas secuencias para inferir un árbol filogenético. Existen muchos paquetes de R que pueden hacer esto y aquí escogemos phangorn para hacer una inferencia basada en **Maximum Likelihood**.
Primero alineamos las secuencias:

```{r}
seqs <- getSequences(seqtabNoC)
# Este paso propaga los nombres de las secuencias al árbol
names(seqs) <- seqs
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
```

Y con ese alineamiento inferimos un árbol de partida o starting tree para inicializar la búsqueda por **Maximum Likelihood** (ML). También ajustamos un modelo de sustitución nucleotídica para parametrizar la tasa de cambio de un nucleótido a otro y así poder inferir correctamente el largo de las ramas y la topología del árbol.

```{r}
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) 
fit <- pml(treeNJ, data = phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
# El modelo de opción en pml sólo se utiliza para los modelos de aminoácidos. 
# El la siguiente función tarda mucho
# fitGTRoptim <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
#        rearrangement = "stochastic", control = pml.control(trace = 0))
# detach("package:phangorn", unload=TRUE)
```

# Metadatos

Ahora, tenemos todos los ingredientes para formar un objeto de R que contenga todo lo que nos importa en un experimento metagenómico, por ejemplo, una *tabla de cuentas* que indica el número de lecturas por seceuncia del gen rRNA 16s, una *tabla con el linaje taxonómico* de esas secuencias, un *árbol filogenético* que relaciona esas secuencias entre sí, y finalmente, una *tabla con variables asociadas* a nuestras muestras, también llamada metadata.

```{r}
samdf <- read.csv("Metadata16s.csv", header=TRUE, row.names = 1)
rownames(seqtabNoC) %in% rownames(samdf)
all(rownames(seqtabAll) %in% samdf$run)
```

# Phyloseq

**Phyloseq** es un paquete de Bioconductor para la manipulación y análisis de datos metagenómicos generados por metodologías de secuenciación de alto rendimiento. **Phyloseq** es una herramienta para *importar*, *guardar*, *analizar* y *visualizar* éste tipo de datos después de haber sido procesados inicialmente, por ejemplo, *ensamblaje de novo*, *ASVs* u *OTUs* (clustered), incluyendo otros importantes datos asociados (si están disponibles): *tabla de observaciones asociadas a cada muestra* (por jemplo: *especie*, *localización geográfica*, *temperatura*, etc.), conocida como sample data o *metadata*, *árbol filogenético*, e *identificación taxonómica* de cada OTU. La estructura del paquete **Phyloseq** consiste en una serie de funciones de acceso y de proceso de objetos phyloseq. Estos objetos están compuestos de cuatro componentes que almacenan las cuentas de reads, la metadata, la taxonomía y el árbol filogenético. El paquete también provee una serie de herramientas para importar datos de otros programas.

Con estos elementos procedemos a generar un objeto phyloseq:
```{r}
ps <- phyloseq(otu_table(seqtabNoC, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxTab),
               phy_tree(fitGTR$tree))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remover potenciales muestras sintéticas
ps
```

 El siguiente diagrama muestra la estructura completa de phyloseq.

```{r}
# Leémos el objeto phyloseq del análisis por DADA2
ps
class(ps)
```

Es más conveniente usar nombres cortos para nuestros ASV (por ejemplo, ASV21) en lugar de la secuencia de ADN completa cuando se trabaja con algunas de las tablas y visualizaciones de phyloseq, pero queremos mantener las secuencias de ADN completas para otros fines, como fusionar con otros conjuntos de datos o la indexación en bases de datos de referencia como Earth Microbiome Project. Por esa razón, almacenaremos las secuencias de ADN de nuestros ASV en la ranura refseq del objeto phyloseq y luego cambiaremos el nombre de nuestros taxones a una cadena corta. De esa forma, los nombres breves de los nuevos taxones aparecerán en tablas y gráficos, y aún podemos recuperar las secuencias de ADN correspondientes a cada ASV según sea necesario con refseq(ps). 

```{r}
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
# Generamos otro archivo con el que empezamos a trabajar
psd <- ps
```

## Control de calidad del análisis de 16S

Lo primero que podemos mirar es la prevalencia de las features taxonómicas. Primero creamos un data frame con los valores de prevalencia, luego les agregamos la taxonomía y graficamos.

```{r}
# Computamos prevalencia para cada feature y la guardamos en un data frame
prevdf <- apply(X = otu_table(psd),
               MARGIN = ifelse(taxa_are_rows(psd), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})

# Le agregamos la taxonomía
prevdf <- data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(psd),
                    tax_table(psd))

plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))}) -> dfprev
kable(dfprev)
```

Al examinar la tabla, es evidente que algunos Phylum aunque presentes, están muy poco representados. La columna 1 representa la media de read counts para ese Phylum, mientras que la columna 2 representa la suma. Por ejemplo, grupos como *Calditrichota* y *Dadabacteria* están representados solamente por 1 read. Es muy riesgoso mantener estos grupos taxonómicos en el análisis ya que pueden corresponder a falsos positivos. Para filtrarlos, generamos un vector con todas las taxa que queremos filtrar.

```{r}
# Definimos taxa a filtrar
filterPhyla <- c("Calditrichota", "Dadabacteria", NA)
# Procedemos a filtrar
psd1 <- subset_taxa(psd, !Phylum %in% filterPhyla)
```

```{r}
# Además aprovechamos a remover taxa que no corresponde a microorganismos como cloroplastos, mitocondrias y otros
filterPhyla2 <- c("Chloroplast", "Mitochondria", "Eukaryota")
psd1 <- subset_taxa(psd1, !Kingdom %in% filterPhyla2)
psd1 <- subset_taxa(psd1, !Phylum %in% filterPhyla2)
psd1 <- subset_taxa(psd1, !Class %in% filterPhyla2)
psd1 <- subset_taxa(psd1, !Order %in% filterPhyla2)
psd1 <- subset_taxa(psd1, !Family %in% filterPhyla2)
psd1 <- subset_taxa(psd1, !Genus %in% filterPhyla2)
```

Además del filtrado que acabamos de realizar, existen otros tipos de filtrado que tienen que ver con la media de cuentas por lectura por taxa, con la distribución de éstas, y con filtrar muestras bajo un número lecturas.

```{r}
# Filtramos taxa de acuerdo a un umbral de número medio de _read counts_, en este caso 1e-5
psd2 <- filter_taxa(psd1, function(x) mean(x) > 1e-5, TRUE)
# También podemos remover taxa que no se observe más de X veces en al menos 10% de las muestras
psd3 <- filter_taxa(psd2, function(x) sum(x > 2) > (0.1*length(x)), TRUE)
# Y finalmente filtrar muestras con menos de 1000 reads
psd4 <- prune_samples(sample_sums(psd3) > 1000, psd3)
psd4
```

Otra forma de filtrar taxa de baja prevalencia es estableciendo un umbral y luego visulizar el efecto de manera grafica.

```{r}
# Seleccionamos las taxa de interés
prevdf1 <- subset(prevdf, Phylum %in% get_taxa_unique(psd4, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(psd),color=Phylum)) +
# Agregamos una línea para nuestro umbral
geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

```{r}
# Definimos el umbral de prevalencia a un 5%
prevalenceThreshold <- 0.05 * nsamples(psd4)
# Ejecutamos un filtro de prevalencia, usando la función `prune_taxa()`
keepTaxa <- rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
psd5 <- prune_taxa(keepTaxa, psd4)
```

**DADA2** usa como nombre de las taxa la secuencia o ASV asociada a un taxon determinado. Esto es conveniente cuando nos interesa la secuencia en nuestros análisis, sin embargo en este práctico solamente vamos a trabajar a nivel de comunidad.
Por esto, vamos a reemplazar esos nombres con códigos correlativos, lo cual va a hacer las visualizaciones posteriores más entendibles.
```{r}
# Reemplazamos las secuencias por un nombre genérico
taxa_names(psd5) <- paste0("ASV", seq(ntaxa(psd5)))
```

## Distribución

Con nuestro objeto phyloseq ya filtrado y listo para usar, podemos gráficar la distribución de read counts por número de muestra de forma de tener una idea sobre la distribución de éstas.

```{r}
sample_sum_df <- data.frame(sum = sample_sums(psd5))

ggplot(sample_sum_df, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "grey", binwidth = 2500) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  theme(axis.title.y = element_blank()) 
```

Finalmente, calculamos curvas de rarefacción para cada muestra, de manera tal que podamos determinar si la profundidad de secuenciación fue sufuciente o si tal vez necesitemos secuenciar más. En otras palabras, este análisis nos permitiría averiguar si al secuenciar más observaríamos más OTUs o ASVs.

```{r}
# Primero cargamos algunos scripts de manera remota
scripts <- c("graphical_methods.R",
             "tree_methods.R",
             "plot_merged_trees.R",
             "specificity_methods.R",
             "ternary_plot.R",
             "richness.R",
             "edgePCA.R",
             "copy_number_correction.R",
             "import_frogs.R",
             "prevalence.R",
             "compute_niche.R")
urls <- paste0("https://raw.githubusercontent.com/mahendra-mariadassou/phyloseq-extended/master/R/", scripts)

for (url in urls) {
  source(url)
}
```

Objeto

```{r}
p <- ggrare(psd5, step = 100, label = "SITE_ID", plot = TRUE, parallel = FALSE, se = TRUE, color = "SITE_ID")
```

Gráfica

```{r}
q <- p + theme_classic2()+
  scale_fill_brewer(palette = "Set1")+
  scale_color_brewer(palette = "Set1")
q
pdf("Resultados/PlotDistribution.pdf", width=10, height=7)
q
dev.off()
svg("Resultados/PlotDistribution.svg", width=10, height=7)
q
dev.off()
pdf("Resultados/PlotDistribution1.pdf", width=10, height=7)
q + facet_wrap("SITE_ID")
dev.off()
svg("Resultados/PlotDistribution1.svg", width=10, height=7)
q + facet_wrap("SITE_ID")
dev.off()
```

## Estructura y manipulación de un objeto phyloseq

Muchas veces queremos analizar un sub conjunto de las muestras en nuestro objeto phyloseq, o bien, queremos seleccionar ciertos grupos taxonómicos para análisis posteriores. Phyloseq nos permite hacer todo tipo de filtros para llevar esto a cabo. Veamos dónde se almacena la información en phyloseq.

```{r}
# Número de taxas
ntaxa(psd5)
# Número de muestras
nsamples(psd5)
# Nombre de las muestras
sample_names(psd5)
# Niveles taxonómicos 
rank_names(psd5)
# Nombre de las variables de los metadatos
sample_variables(psd5)
```

La tabla de cuentas relaciona el nombre de las taxa con las muestras y con el número de lecturas mapeadas en contra de ellas. Acá el número de lecturas es directamente proporcional al número de veces que se observa un taxon.
El otro componente importante es la tabla de taxonomía.

```{r}
# Tabla de cuentas
otu_table(psd5)[1:5, 1:5]
```

La tabla de taxonomía relaciona el nombre de las taxa con el linaje taxonómico de éstas, por ejemplo, vincula una variante de secuencia, o ASV, con los rangos taxonómicos desde Reino hasta Género o Especie dependiendo del nivel de resolución del análisis.

```{r}
# Tabla de taxonomía
tax_table(psd5)[1:5, 1:4]
```

Finalmente, tenemos el árbol filogenético, que es opcional en phyloseq, que nos muestra las relaciones evolutivas entre las taxa de todas las muestras. Es opcional porque normalmente cuando hacemos shotgun metagenomics no contamos con un marcador universal y por lo tanto no hay filogenia. Podemos graficar simplemente la filogenia con la función plot_tree.

```{r}
# Esta es la filogenia asociada a las taxa en nuestro objeto phyloseq
plot_tree(psd5, method = "treeonly", ladderize = "left")

phy_tree(psd5)
taxa_names(psd5)[1:10]

# Probamos quedandonos solo los primeros 10 taxa con mayor presencia 
myTaxa <- names(sort(taxa_sums(psd5), decreasing = TRUE)[1:10])
ex1 <- prune_taxa(myTaxa, psd5)
plot(phy_tree(ex1), show.node.label = TRUE)
```

Podemos hacer un árbol a nivel de *Phylum*

```{r}
Dendro <- plot_tree(psd5, color="Phylum", base.spacing = 0.03) +
  facet_wrap("SITE_ID")+
  theme_classic()+ 
  labs(x="Sample", y="OTUs",
       title="Phylogenetic tree of the phylum")+
  theme(legend.position = "right", 
        legend.text = element_text(size=12, face="bold"),
        legend.title = element_text(size = 12, face = "bold"),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text = element_text(color = "black", size = 12, face = "bold"),
        axis.title = element_text(color = "black", size = 12, face = "bold"),
        plot.title = element_text(hjust = 0.5, size=14, face="bold"))
print(dendro)
pdf("Resultados/Dendogramas/PlotTreePhylum.pdf", width=15, height=7)
print(dendro)
dev.off()
svg("Resultados/Dendogramas/PlotTreePhylum.svg", width=15, height=7)
print(dendro)
dev.off()
```

Ahora, el objeto phyloseq se ha vuelto un estándar en la industria ya que otros paquetes ahora usan esta estructura de datos para sus propias funciones. Uno de esos paquetes es *microbiome* y *ampvis*. Podemos fácilmente obtener un resumen global de nuestro objeto phyloseq usando la función summarize_phyloseq.

```{r}
summarize_phyloseq(psd5)
```

Este comando nos muestra el mínimo y máximo de reads, número total y promedio de reads, etc. También muestra los encabezados de las columans en la tabla de metadata. Veamos ahora una tabla que mezcla metadata, taxonomía y abundancia del taxon más abundante de cada muestra.

```{r}
df <- psmelt(psd5)
df
```

También es importante tener una visión de cómo se distribuyen las muestras de acuerdo a la metadata. En este ejemplo, graficamos la frecuencia:

```{r}
res <- plot_frequencies(sample_data(psd5), "SITE_ID", "P_OLSEN")
res
```

Ahora veamos cómo podemos filtrar y hacer subsetting de un objeto phyloseq. Esto lo hacemos con tres grupos de funciones, por ejemplo, `filter`, `subset`, y `prune`. 
+ Filtrar se refiere a filtrar según alguna regla lógica. Ya lo hicimos en la parte de control de calidad cuando llamamos la función `filter_taxa(psd1, function(x) mean(x) > 1e-5, TRUE)`. Acá le pedíamos a la función `filter_taxa` sobre el objeto psd5, calculara la media de cuentas de lecturas para cada taxa y si este resultado era menor que 1e-5, lo eliminara. Ahora filtramos según abundancia.
Primero transformamos en abundancia relativa y luego filtramos.

```{r}
# Transformamos las cuentas en porcentaje
psd5r <- transform_sample_counts(psd5, function(x) x / sum(x) * 100 )
# Filtramos las taxa con una abundancia inferior al 1%
psd5r.filtrado <- filter_taxa(psd5r, function(x) sum(x) > 1, TRUE)
```

¿Cuántas taxa permanecen en nuestro objeto phyloseq? Con una operación tan simple como la que acabamos de aplicar, nos damos cuenta que la mayoría de las taxa presentes en nuestras están en muy baja abundancia. Ahora imaginemos la situación donde queremos filtrar nuestro objeto pero en función de un taxon en específico.

```{r}
# Ahora filtramos de acuerdo a Acidobacteriota
subset_taxa(psd5r.filtrado, Phylum == "Acidobacteriota") -> psd5r.filtrado.Acidobacteriota
# También podríamos todo lo que NO es Acidobacteriota
subset_taxa(psd5r.filtrado, Phylum != "Acidobacteriota") -> psd5r.filtrado.NoAcidobacteriota
```

Otra manera de filtrar un objeto phyloseq es en base a algún atributo presente en `sample_data`. Por ejemplo, con estos datos uno podría querer estudiar el microbioma de área por separado. Para esto crearíamos tres objetos phyloseq a partir de psd5.

```{r}
psd5.Ag1 <- subset_samples(psd5, SITE_ID == "Ag1")
psd5.Ag2 <- subset_samples(psd5, SITE_ID == "Ag2")
psd5.Ag3 <- subset_samples(psd5, SITE_ID == "Ag3")
```

Alternativamente, podríamos decidir estudiar solo dos de las 3 áreas
```{r}
psd5.Ag1_Ag2 <- subset_samples(subset_samples(psd5, SITE_ID != "Ag3"))
```

## Datos absolutos y relativos

Generamos una tabla de datos absolutos y relativos, para posteriores análisis.

```{r}
Relativos <- transform_sample_counts(psd5, function(x) x*100 / sum(x))
# Valores relativos
Glom_Rel <- tax_glom(physeq = Relativos, taxrank = 'Phylum')
# psmelt permite generar un data.frame a partir de un objeto de phyloseq
Relativos <- psmelt(Glom_Rel)
# Valores absolutos
Glom_Abs <- tax_glom(physeq = psd5, taxrank = "Phylum")
Absolutos <- psmelt(Glom_Abs)
```

### Dendogramas

A continuación haremos los dendogramas de todas los *phylum* y *género*
El comando `prune_samples()` también es muy usado ya que nos permite usar un vector con las muestras que queremos mantener (similar a `subset_samples`) o un vector lógico donde las muestras que queremos mantener son verdaderas.

```{r}
OnePercentage <- unique(Relativos$Phylum[Relativos$Abundance > 1.0])
OnePercentage
```

Ciclo para hacer todos los dendogramas con mayor al 1 % en abundancia relativa

```{r}
for (i in OnePercentage){
  # Prueba 
  # i <- "Actinobacteriota"
  # Primero seleccionamos solo el Phylum
  Sub <- subset_taxa(psd5, Phylum == i)
  # Filtramos por abundancia mayor a 5 reads
  Sub <- prune_samples(sample_sums(Sub) >= 5, Sub) 
  # Vemos resultados en un Dendograma
  tryCatch({
  dendro <- plot_tree(Sub, color = "Genus", size = "abundance", base.spacing = 0.03) +
    facet_wrap("SITE_ID") +
    theme_classic() +
    labs(x = "Sample", y = "OTUs",
         title = paste0("Phylogenetic tree of the Phylum ", i)) +
    theme(legend.position = "right", 
        legend.text = element_text(size=12, face="bold"),
        legend.title = element_text(size = 12, face = "bold"),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text = element_text(color = "black", size = 12, face = "bold"),
        axis.title = element_text(color = "black", size = 12, face = "bold"),
        plot.title = element_text(hjust = 0.5, size=14, face="bold"))
  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")}) 
  dendro
  pdf(paste0("Resultados/Dendogramas/PlotTree", i, ".pdf"), width = 20, height = 10)
  print(dendro)
  dev.off()
  svg(paste0("Resultados/Dendogramas/PlotTree", i, ".svg"), width = 20, height = 10)
  print(dendro)
  dev.off()
}
```


```{r}
# Primero seleccionamos solo el Phylum Acidobacteriota
subset_taxa(psd5, Phylum=="Acidobacteriota") -> psd5.Acidobacteriota
# Luego nos quedamos con las muestras que solo cumplen con la condición, i,e, que poseen una abundancia de Acidobacteriota de más de 5 reads
prune_samples(sample_sums(psd5.Acidobacteriota)>=5, psd5.Acidobacteriota) -> psd5.Acidobacteriota
# Y finalmente visualizamos los resultados mapeados en el árbol filogenético
tree.acido <- plot_tree(psd5.Acidobacteriota, color="Genus", size = "abundance", base.spacing = 0.03) +
  facet_wrap("SITE_ID")+ 
  theme_classic()+ 
  labs(x="Sample", y="OTUs",
       title="Phylogenetic tree of the phylum Acidobacteriota")+
  theme(legend.position = "right", 
        legend.text = element_text(size=12, face="bold"),
        legend.title = element_text(size = 12, face = "bold"),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text = element_text(color = "black", size = 12, face = "bold"),
        axis.title = element_text(color = "black", size = 12, face = "bold"),
        plot.title = element_text(hjust = 0.5, size=14, face="bold"))
tree.acido
pdf("Resultados/PlotTreeAcido.pdf", width=, height=7)
tree.acido
dev.off()
svg("Resultados/PlotTreeAcido.svg", width=15, height=7)
tree.acido
dev.off()
```

Para finalizar esta sección, un par de funciones muy útiles en phyloseq son `tax_glom()` y `tip_glom()`. Ambas funciones tratan de agrupar o aglomerar un objeto de acuerdo a alguna propiedad, de esta manera simplificándolo. Por ejemplo, es muy probable que uno tenga varias ASVs del mismo género ya que si bien a nivel de secuencia son diferentes, estas corresponden al mismo género.
Para hacer visualizaciones y otros análisis puede ser conveniente colapsar o aglomerar estas secuencias del mismo género u otro rango taxonómico. Al mismo tiempo, `tip_glom()` realiza una función similar pero basándose en una “altura” arbitraria en el árbol filogenético.

```{r}
# Primero aglomeramos por género
psd5.genus <- tax_glom(psd5, "Genus", NArm = FALSE)
# Luego por altura en el árbol filogenético
h1 <-  0.2
psd5.tip <- tip_glom(psd5, h = h1)
# Grafiquemos una comparación para visualizar las diferencias
multiPlotTitleTextSize = 15
p2tree <- plot_tree(psd5, method = "treeonly",
                   ladderize = "left",
                   title = "Sin aglomeración") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree <- plot_tree(psd5.genus, method = "treeonly",
                   ladderize = "left", title = "A nivel de género") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree <- plot_tree(psd5.tip, method = "treeonly",
                   ladderize = "left", title = "Por altura") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))

# Graficamos los árboles juntos
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```

## Ensamble y manipulación de objetos de **Phyloseq**

```{r}
psd5
sample_sums(x = psd5)
summary(psd5@otu_table@.Data)
```